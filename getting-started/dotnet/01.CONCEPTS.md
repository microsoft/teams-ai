### How an incoming activity is routed in the Application:

When an incomming activity reaches the server, the bot adapter handles the necessary authentication and creates a `TurnContext` object that encapsulates the activity details. It then calls the `OnTurnAsync` method. This is the entry point method of the application. Here's what happens in this method:

1. If configured in the application options, pulses of the `Typing` activity is sent to the user.
2. If configured in the application options, the @mention is removed from the incomming message activity.
3. The turn state is loaded using the configured turn state manager.
4. The `OnBeforeTurnAsync` activity handler is executed. If it returns false, save turn state to storage.
5. If the corresponding activity handler is configured, then it is executed. Otheriwse the AI module's `ChainAsync` executes.
6. The `AfterTurnAsync` activity handler is executed. If it return true, save turn state to storage.

These 6 steps happen every time an incomming activity is received by the server. 

Here's a high level overview:

![Alt text](image.png)

<!-- 
Fixes that need to be made to the diagram:

1. Change "Bot Server" to "Application"
2. Change "Configure Turn State" to Load TurnState from storage.
3. Beautify the diagram is it makes sense.

-->

<!-- ### What ties the AI module together: The `ChainAsync` method

It would be a good idea to walk through how the steps the `ChainAsync` method takes for an incomming request from the light bot.
1. The prompt that gets rendered.
2. The model's response
3. Show that the response is parsed into a Plan object - explain what a SAY/DO command is
4. Show the custom user registered actions executing.

The goal with this section is to show a concrete example of what exactly is happening in the works. In the samples the model request and response is console-logged so it would be a good idea to show it here as well.