# Migrating from Botbuilder SDK to Teams AI.

Previously, users developing bots for Teams and Microsoft 365 apps used the BotBuilder SDK. The Teams-AI SDK is designed to help you build bots that can interact with Teams and Microsoft 365 apps.

While one of the exciting features of this SDK is the AI support that customers will be able to migrate to, your team's first goals might be simply to update your current bot without AI.

These directions will apply both to non-AI and AI bot migration.

> Please note: the formatting below does not necessarily follow traditional dotnet conventions. This was purposefully done to make instantly viewing the differences easier.

The first samples [C#](../dotnet/samples)] | [JS](../js/samples/)] available assist in migrating these features.

> Note: [Teams samples](https://github.com/OfficeDev/Microsoft-Teams-Samples) are currently available. These samples will be updated to use this SDK in the future.

### Update the ActivityHandler

In the BotFramework SDK the Bot class extended the `TeamsActivityHandler` class. In Teams AI you will replace that with the `Application<TurnState, TurnStateManager>` class.

```diff
- public class EchoBot : TeamsActivityHandler { }

+ public class EchoBot : Application<TurnState, TurnStateManager> {
+
+    public EchoBot(ApplicationOptions<TurnState, TurnStateManager> options) : base(options) {}
+ }
```

> The `TurnState` and `TurnStateManager` are classes that make up the turn state infrastructure. The generic types in the `Application` class allow users to customize the shape of the turn state.

The activity handling method is the same for both (previous) `TeamsActivityHandler` and (new) `Application` class, except for a few nuances. See below for more.

#### New turn state parameter:

`TState turnState` has been added as a parameter to `OnMessageActivityAsync`.

```diff
protected virtual Task OnMessageActivityAsync(
    ITurnContext<IMessageActivity> turnContext,
+   TState turnState,
    CancellationToken cancellationToken);
```

#### Drop the `Teams` prefix:

`onTeamsChannelCreatedAsync` is modified to `OnChannelCreatedAsync`.

```diff
protected virtual Task
-    OnTeamsChannelCreatedAsync(
+    OnChannelCreatedAsync(
        ChannelInfo channelInfo,
        TeamInfo teamInfo,
        ITurnContext<IConversationUpdateActivity> turnContext,
        TState turnState,
        CancellationToken cancellationToken);
```

#### Reorder parameters for consistency:

> Note that in `OnSearchInvokeAsync`, the parameter `SearchInvokeValue: invokeValue` has been moved to the first parameter, to precede `ITurnContext<IInvokeActivity>: turnContext`. `CancellationToken cancellationToken` remains as the last parameter.

```diff
protected virtual Task<SearchInvokeResponse> OnSearchInvokeAsync(
      SearchInvokeValue invokeValue,
      ITurnContext<IInvokeActivity> turnContext,
+     TState turnState,
      CancellationToken cancellationToken);
```

For every activity handler method in the BotFramework SDK, users can replace it with a corresponding method in the `Application` class.

This is all it takes to port over to Teams AI!

Next, the exciting step is to add AI to your bot! Continue on to [01.AI-SETUP](01.AI-SETUP.md)

Otherwise, see below for in-depth explanation of porting-related concepts.

## How an incoming activity is routed in the Application:

When an incoming activity reaches the server, the bot adapter handles the necessary authentication and creates a `TurnContext` object that encapsulates the activity details. It then calls the `OnTurnAsync` method. This is the entry point method of the application. Here's what happens in this method:

1. If configured in the application options, pulses of the `Typing` activity are sent to the user.
2. If configured in the application options, the @mention is removed from the incoming message activity.
3. The turn state is loaded using the configured turn state manager.
4. The `OnBeforeTurnAsync` activity handler is executed. If it returns false, save turn state to storage.
5. All text-based messages are handled through `OnMessageActivityAsync`. If there is an AI setup and `OnMessageActvityAsync` throws a `NotImplementedException`, then `ChainAsync` is called and executed.
6. The `AfterTurnAsync` activity handler is executed. If it return true, save turn state to storage.

These six steps happen every time an incoming activity is received by the server.

### Application turn flow

If you are familiar with botbuilder, you already know the basics of turn flow in Teams AI. The main differences are `BeforeTurn`, `AfterTurn`, and how AI fits into the system.

![diagram of Teams AI application flow](../assets/image.png)

1. The change in flow begins when an activity handler is not registered with the app. If that is the case, the turn context and turn state is passed to the AI module.
1. The AI module will determine its response via the prompt (which may include conversation history)

```dotnet
[Action("ActionName")]
        public async Task<bool> ActionName([ActionTurnContext] ITurnContext turnContext, [ActionTurnState] AppState turnState) { ... }
```

The above is the setup for a specific action.

1. The AI module generates a plan of actions on what to do with the response that was generated. (More details provided in <a href="#what-ties-the-ai-module-together-action-mapping">AI Module</a> section)
1. The module will execute those actions, and fill its response (`$output`) with the appropriate data.
1. The response is passed to `AfterTurn`, in `TempState` includes:
   - `$history` - AI or conversation history, the length (number of turns) of which is determined by the prompt configuration
   - `$input` - the user's original input
   - `$output` - the generated response by the AI
1. `AfterTurn` is intended to be used for cleanup after the response has been sent.

Note that Bot memory and AI memory are distinct.

### Bot memory

> Bot memory and AI memory are separate. Bot memory stores data for the bot to use, while AI memory stores AI data.

- `$conversation.<prop>` - bot conversation memory
- `$user.<prop>` - bot user memory
- `$temp.<prop>` - bot temp memory (data kept for 1 turn only)
  - `$<prop>` may be used as an alias for `$temp.<prop>`

## AI memory (`$history`)

> AI bot memory may store context/information for as little as 1 turn, while bot memory may be used to store information for the lifetime of the conversation.

> Unlike bot memory, AI memory consumes tokens and therefore is more expensive, but keeping a shorter `$history` may cause more frequent hallucinations from the AI.

- `$history` - conversation history tracked by AI (not related to bot's conversation history see [Bot memory](#bot-memory))
- `$input` - input from the prompt, such as `activity.text`
- `$output` - the last executed function's output. You reference this output in code as `state.temp.value.output`
- Hallucinatiion - when the AI creates an independant context/response that does not match the app's use-cases.
- Parent prompt: when executing chaining, the output from the child prompt may be directly passed to the parent prompt:

## What ties the AI module together: Action Mapping

`ChainAsync` is utilized when the Planner recieves an input that did not trigger an activity handler, and instead generates and implements a plan. That plan is the list of directions that the LLM will follow according to the predicted action from the user's input. For example, in action mapping LightBot, the following excerpt is a section of the plan:

### DO and SAY

```txt
The assistant must return the following JSON structure:

{"type":"plan","commands":[{"type":"DO","action":"<name>","entities":{"<name>":<value>}},{"type":"SAY","response":"<response>"}]}

The following actions are supported:

- LightsOn
- LightsOff
- Pause time=<duration in ms>
- LightStatus
```

The first two lines of directions asserts that the AI _must_ return its response in JSON format. This means that `$output` will return JSON, and therefore be parsable in a predictable way.

- The JSON provided is minified to reduce token ussage
- There are two types of commands: `DO` and `SAY`

The commands are provided as an array to perform in order.

- `DO` is an action defined by your code in `LightBotActions.cs`. These are programmatic methods not defined in natural language, but in your code.
  - In the prompt above, the performable `DO` actions are `LightsOn`, `LightsOff`, `Pause`, and `LightStatus`
- `SAY` is a response to add to the conversation, exactly like the response from a bot.
